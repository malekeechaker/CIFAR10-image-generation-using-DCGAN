{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-03T14:13:19.012270Z","iopub.execute_input":"2024-11-03T14:13:19.012684Z","iopub.status.idle":"2024-11-03T14:13:20.713860Z","shell.execute_reply.started":"2024-11-03T14:13:19.012644Z","shell.execute_reply":"2024-11-03T14:13:20.712843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport imageio","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:16:11.250510Z","iopub.execute_input":"2024-11-03T14:16:11.250915Z","iopub.status.idle":"2024-11-03T14:16:11.320029Z","shell.execute_reply.started":"2024-11-03T14:16:11.250879Z","shell.execute_reply":"2024-11-03T14:16:11.319257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset CIFAR-10","metadata":{}},{"cell_type":"code","source":"# Charger le dataset CIFAR-10\n(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n\n# Normaliser les images d'entraînement et de test pour qu'elles soient entre -1 et 1\ntrain_images = (train_images - 127.5) / 127.5\ntest_images = (test_images - 127.5) / 127.5\n\n# Vérifier la forme des datasets pour s'assurer que la normalisation est correcte\nprint(\"Shape des images d'entraînement :\", train_images.shape)\nprint(\"Valeur minimum des images d'entraînement :\", train_images.min())\nprint(\"Valeur maximum des images d'entraînement :\", train_images.max())\n\nprint(\"Shape des images de test :\", test_images.shape)\nprint(\"Valeur minimum des images de test :\", test_images.min())\nprint(\"Valeur maximum des images de test :\", test_images.max())\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:13:38.200100Z","iopub.execute_input":"2024-11-03T14:13:38.200642Z","iopub.status.idle":"2024-11-03T14:13:58.793193Z","shell.execute_reply.started":"2024-11-03T14:13:38.200606Z","shell.execute_reply":"2024-11-03T14:13:58.792272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(10000).batch(256)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:13:58.794333Z","iopub.execute_input":"2024-11-03T14:13:58.794639Z","iopub.status.idle":"2024-11-03T14:14:02.473747Z","shell.execute_reply.started":"2024-11-03T14:13:58.794606Z","shell.execute_reply":"2024-11-03T14:14:02.472879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fonction pour afficher un échantillon d'images\ndef display_sample_images(images, num_images=25):\n    plt.figure(figsize=(10, 10))\n    for i in range(num_images):\n        plt.subplot(5, 5, i + 1)  # Grille 5x5\n        plt.imshow((images[i] + 1) / 2)  # Re-normaliser entre 0 et 1 pour l'affichage\n        plt.axis('off')  # Masquer les axes\n    plt.show()\n\n# Afficher un échantillon d'images d'entraînement\ndisplay_sample_images(train_images)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:02.476812Z","iopub.execute_input":"2024-11-03T14:14:02.477206Z","iopub.status.idle":"2024-11-03T14:14:03.417200Z","shell.execute_reply.started":"2024-11-03T14:14:02.477163Z","shell.execute_reply":"2024-11-03T14:14:03.416213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create GAN Fonctions","metadata":{}},{"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense (8*8*256, use_bias=False, input_shape=(100,))) \n    model.add(layers. BatchNormalization())\n    model.add(layers. LeakyReLU())\n    model.add(layers. Reshape((8, 8, 256)))\n    assert model.output_shape == (None, 8, 8, 256)  #test a condition, if true continue else error\n    # None représente la taille du batch\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers. BatchNormalization())\n    model.add(layers. LeakyReLU())\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers. BatchNormalization())\n    model.add(layers. LeakyReLU())\n    model.add(layers. Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation= 'tanh')) \n    assert model.output_shape == (None, 32, 32, 3)\n    return model\n\ndef make_discriminator_model():\n    model = tf.keras. Sequential()\n    model.add(layers. Conv2D (64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n    model.add(layers. LeakyReLU())\n    model.add(layers. Dropout (0.3))\n    model.add(layers.Conv2D (128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers. Dropout (0.3))\n    model.add(layers. Flatten())\n    model.add(layers. Dense (1))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:03.418335Z","iopub.execute_input":"2024-11-03T14:14:03.418617Z","iopub.status.idle":"2024-11-03T14:14:03.430860Z","shell.execute_reply.started":"2024-11-03T14:14:03.418586Z","shell.execute_reply":"2024-11-03T14:14:03.429916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Définition de la fonction de perte pour l'entropie croisée binaire\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n# Fonction de perte pour le discriminateur\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)    # le modèle doit prédire 1    \n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)   # le modèle doit prédire 0\n    # Somme des deux pertes\n    total_loss = real_loss + fake_loss\n    return total_loss\n\n# Fonction de perte pour le générateur\ndef generator_loss(fake_output):\n    # Le générateur essaie de faire classer les fausses images comme réelles (1)\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n# Définition des optimiseurs pour les deux modèles\ngenerator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:03.432089Z","iopub.execute_input":"2024-11-03T14:14:03.432454Z","iopub.status.idle":"2024-11-03T14:14:03.451934Z","shell.execute_reply.started":"2024-11-03T14:14:03.432411Z","shell.execute_reply":"2024-11-03T14:14:03.450941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualise an image generation without training","metadata":{}},{"cell_type":"code","source":"# Initialiser les modèles générateur et discriminateur\ngenerator = make_generator_model()\ndiscriminator = make_discriminator_model()\n\n# Générer une image avec le générateur non entraîné\nnoise = tf.random.normal([1, 100])  # Bruit d'entrée pour le générateur\ngenerated_image = generator(noise, training=False)  # Générer une image\n\nview_generated_image = (generated_image[0] + 1) / 2.0\n\n# Afficher l'image générée\nplt.imshow(view_generated_image)\nplt.axis('off')  # Masquer les axes pour une meilleure visualisation\nplt.show()\n# Évaluer l'image générée avec le discriminateur non entraîné\ndecision = discriminator(generated_image, training=False)\n\n# Afficher les résultats\nprint(\"Image générée (forme) :\", generated_image.shape)\nprint(\"Sortie du discriminateur pour l'image générée :\", decision.numpy())\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:03.453167Z","iopub.execute_input":"2024-11-03T14:14:03.453535Z","iopub.status.idle":"2024-11-03T14:14:05.723162Z","shell.execute_reply.started":"2024-11-03T14:14:03.453490Z","shell.execute_reply":"2024-11-03T14:14:05.722168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a Fonction to vizualise a grid of images every epoch","metadata":{}},{"cell_type":"code","source":"# Fonction pour afficher les images générées en grille\ndef display_images(images, epoch=None):\n    plt.figure(figsize=(4, 4))\n    for i in range(images.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        img = (images[i] + 1) / 2.0  # Redimensionner l'image pour être entre 0 et 1\n        plt.imshow(img)\n        plt.axis('off')\n\n    if epoch is not None:\n        plt.suptitle(f\"Images générées à l'époque {epoch}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:05.724245Z","iopub.execute_input":"2024-11-03T14:14:05.724547Z","iopub.status.idle":"2024-11-03T14:14:05.731867Z","shell.execute_reply.started":"2024-11-03T14:14:05.724514Z","shell.execute_reply":"2024-11-03T14:14:05.730994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Définir la dimension du bruit\nnoise_dim = 100\n\n# Créer un vecteur de bruit constant pour visualiser les progrès au cours des époques\n# Générer 16 vecteurs de bruit pour obtenir 16 images\nnum_examples_to_generate = 16\nfixed_seed = tf.random.normal([num_examples_to_generate, noise_dim])\n\ngenerator = make_generator_model()\n\n# Générer des images en utilisant le vecteur de bruit fixe\ngenerated_images = generator(fixed_seed, training=False)\n\n# Afficher les images générées\ndisplay_images(generated_images)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:05.733455Z","iopub.execute_input":"2024-11-03T14:14:05.734257Z","iopub.status.idle":"2024-11-03T14:14:06.491443Z","shell.execute_reply.started":"2024-11-03T14:14:05.734217Z","shell.execute_reply":"2024-11-03T14:14:06.490493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Train fonction","metadata":{}},{"cell_type":"markdown","source":"`@tf.function` optimise et accélère l'exécution d'une fonction TensorFlow en la transformant en un graphe de calcul efficace, idéal pour des opérations intensives comme l'entraînement de réseaux de neurones.\n\n`with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape`: creates two separate context managers for automatic differentiation in TensorFlow, allowing you to compute gradients for both the generator (gen_tape) and discriminator (disc_tape) models simultaneously during the training step.","metadata":{}},{"cell_type":"code","source":"# Define the training step function\n@tf.function\ndef train_step(images):\n    # Generate random noise for the generator\n    noise = tf.random.normal([images.shape[0], noise_dim])\n\n    # Use a GradientTape to track the operations for automatic differentiation\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        # Generate fake images from the noise\n        generated_images = generator(noise, training=True)\n\n        # Get the discriminator output for real and fake images\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        # Calculate the loss for the discriminator and generator\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    # Calculate the gradients for both models\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    # Apply the gradients to the optimizers\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n    # Return the losses to monitor training\n    return gen_loss, disc_loss","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:14:06.492953Z","iopub.execute_input":"2024-11-03T14:14:06.493575Z","iopub.status.idle":"2024-11-03T14:14:06.503424Z","shell.execute_reply.started":"2024-11-03T14:14:06.493531Z","shell.execute_reply":"2024-11-03T14:14:06.502389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_dim = 100\nnum_examples_to_generate = 16\nfixed_seed = tf.random.normal([num_examples_to_generate, noise_dim])\n\ndef generate_and_save_images(model, epoch, test_input):\n    # Générer des images à partir du bruit d'entrée\n    generated_images = model(test_input, training=False)\n\n    # Configurer la taille de la figure pour afficher les images\n    plt.figure(figsize=(4, 4))\n    for i in range(generated_images.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        # Normaliser l'image pour qu'elle soit entre 0 et 1\n        img = (generated_images[i] + 1) / 2.0\n        plt.imshow(img)\n        plt.axis('off')  # Masquer les axes\n\n    # Enregistrer la figure sous forme d'image PNG\n    plt.savefig(f'generated_images_epoch_{epoch}.png')  # Nom du fichier avec l'époque\n    plt.close()  # Fermer la figure pour libérer de la mémoire","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:19:37.281834Z","iopub.execute_input":"2024-11-03T14:19:37.282221Z","iopub.status.idle":"2024-11-03T14:19:37.290478Z","shell.execute_reply.started":"2024-11-03T14:19:37.282185Z","shell.execute_reply":"2024-11-03T14:19:37.289572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fonction d'entraînement\ndef train(dataset, epochs):\n    # Itérer sur le nombre d'époques\n    for epoch in range(epochs):\n        # Boucle sur chaque lot d'images dans le dataset\n        for image_batch in dataset:\n            gen_loss, disc_loss = train_step(image_batch)\n        generate_and_save_images(generator, epoch + 1, fixed_seed)  # Générer des images après chaque époque\n\n        # Afficher un message de progression\n        print(f'Epoque {epoch + 1}, Perte du Générateur: {gen_loss.numpy()}, Perte du Discriminateur: {disc_loss.numpy()}')\n\n        # Générer des images à partir d'un bruit fixe pour visualiser les progrès\n        generated_images = generator(fixed_seed, training=False)  # Utiliser le vecteur de bruit fixe\n        #display_images(generated_images, epoch + 1)  # Afficher les images générées","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:19:42.672962Z","iopub.execute_input":"2024-11-03T14:19:42.673368Z","iopub.status.idle":"2024-11-03T14:19:42.679301Z","shell.execute_reply.started":"2024-11-03T14:19:42.673332Z","shell.execute_reply":"2024-11-03T14:19:42.678206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exécuter l'entraînement\ntrain(train_dataset, epochs=1000)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:19:44.845414Z","iopub.execute_input":"2024-11-03T14:19:44.846282Z","iopub.status.idle":"2024-11-03T14:20:24.318691Z","shell.execute_reply.started":"2024-11-03T14:19:44.846243Z","shell.execute_reply":"2024-11-03T14:20:24.317416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a gif form generated images in epochs","metadata":{}},{"cell_type":"code","source":"# Fonction pour afficher une image spécifique basée sur l'époque\ndef display_image(epoch):\n    # Charger l'image générée à partir d'un fichier\n    img = mpimg.imread(f'generated_images_epoch_{epoch}.png')\n    \n    # Afficher l'image\n    plt.imshow(img)\n    plt.axis('off')  # Masquer les axes\n    plt.title(f'Image générée à l\\'époque {epoch}')  # Titre de l'image\n    plt.show()\n\n# Exemple d'utilisation\ndisplay_image(epoch=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:21:07.174800Z","iopub.execute_input":"2024-11-03T14:21:07.175536Z","iopub.status.idle":"2024-11-03T14:21:07.379237Z","shell.execute_reply.started":"2024-11-03T14:21:07.175476Z","shell.execute_reply":"2024-11-03T14:21:07.378328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio.v2 as imageio  # Importer imageio v2\nimport os\n\n# Fonction pour créer un GIF animé à partir des images sauvegardées\ndef create_gif_from_images(gif_name='progress.gif', num_epochs=10):\n    with imageio.get_writer(gif_name, mode='I', duration=0.5) as writer:\n        for epoch in range(1, num_epochs + 1):\n            # Vérifier si l'image existe avant de l'ajouter au GIF\n            image_path = f'/kaggle/working/generated_images_epoch_{epoch}.png'\n            if os.path.exists(image_path):\n                image = imageio.imread(image_path)  # Utiliser imageio.v2.imread\n                writer.append_data(image)\n\n# Exemple d'utilisation\ncreate_gif_from_images(num_epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:21:10.610038Z","iopub.execute_input":"2024-11-03T14:21:10.610781Z","iopub.status.idle":"2024-11-03T14:21:10.683314Z","shell.execute_reply.started":"2024-11-03T14:21:10.610741Z","shell.execute_reply":"2024-11-03T14:21:10.682338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\n\n# Chemin du GIF\ngif_path = 'progress.gif'\n\n# Afficher le GIF avec IPython\nHTML(f'<img src=\"{gif_path}\" alt=\"progress gif\">')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T14:21:18.139604Z","iopub.execute_input":"2024-11-03T14:21:18.140381Z","iopub.status.idle":"2024-11-03T14:21:18.147222Z","shell.execute_reply.started":"2024-11-03T14:21:18.140342Z","shell.execute_reply":"2024-11-03T14:21:18.146182Z"},"trusted":true},"execution_count":null,"outputs":[]}]}